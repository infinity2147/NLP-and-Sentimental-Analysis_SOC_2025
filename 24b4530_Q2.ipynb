{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72d529e9-0e4b-40b3-8ecb-f56488149e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping the texts to observe the similarities\n",
    "#1 tech\n",
    "text1 = \"Artificial intelligence is transforming the world.\"\n",
    "text2 = \"Machine learning algorithms require a lot of data.\"\n",
    "text3 = \"Python is a versatile language used in many domains.\"\n",
    "text4 = \"Natural language processing helps machines understand humans.\"\n",
    "text5 = \"Data science combines statistics, coding, and domain expertise.\"\n",
    "text6 = \"Space exploration requires cutting-edge technology.\"\n",
    "#2 Nature & Environment \n",
    "text7 = \"The sun rises in the east and sets in the west.\"\n",
    "text8 = \"The weather today is sunny with a chance of rain.\"\n",
    "text9 = \"Climate change is affecting wildlife across the globe.\"\n",
    "text10 = \"She is writing a research paper on climate change.\"\n",
    "#3: Learning & Education (Text 11–15)\n",
    "text11 = \"Online education has become more popular after the pandemic.\"\n",
    "text12 = \"Reading books improves vocabulary and imagination.\"\n",
    "text13 = \"He studies computer science at a reputed university.\"\n",
    "text14 = \"She bought a new laptop for her graphic design course.\"\n",
    "text15 = \"Time management is crucial for student productivity.\"\n",
    "#4: Daily Life & Hobbies (Text 16–20)\n",
    "text16 = \"He loves playing football every weekend.\"\n",
    "text17 = \"The cat sat on the windowsill, watching the birds.\"\n",
    "text18 = \"She enjoys baking cakes and cookies during weekends.\"\n",
    "text19 = \"This restaurant serves the best pasta in town.\"\n",
    "text20 = \"Traveling opens up new perspectives on life.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72be283a-1e1a-4cf7-92ee-0465004b5d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    text1, text2, text3, text4, text5,\n",
    "    text6, text7, text8, text9, text10,\n",
    "    text11, text12, text13, text14, text15,\n",
    "    text16, text17, text18, text19, text20\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d78959c-0092-4c24-aa56-70baae56f798",
   "metadata": {},
   "source": [
    "1. Bag of Words (BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9c510c7-1371-4287-86ef-26fa33d031d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "babac74e-d509-40c7-9bef-3089fb062149",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_bow = vectorizer.fit_transform(corpus)\n",
    "bow_feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b10c803-f18a-4937-84f7-70add54d8d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 98)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_matrix_shape = X_bow.toarray().shape\n",
    "bow_matrix_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73213f0b-32f6-49c8-a446-672aff108a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['affecting' 'algorithms' 'artificial' 'baking' 'best' 'birds' 'books'\n",
      " 'bought' 'cakes' 'cat' 'chance' 'change' 'climate' 'coding' 'combines'\n",
      " 'computer' 'cookies' 'course' 'crucial' 'cutting' 'data' 'design'\n",
      " 'domain' 'domains' 'east' 'edge' 'education' 'enjoys' 'expertise'\n",
      " 'exploration' 'football' 'globe' 'graphic' 'helps' 'humans' 'imagination'\n",
      " 'improves' 'intelligence' 'language' 'laptop' 'learning' 'life' 'lot'\n",
      " 'loves' 'machine' 'machines' 'management' 'natural' 'new' 'online'\n",
      " 'opens' 'pandemic' 'paper' 'pasta' 'perspectives' 'playing' 'popular'\n",
      " 'processing' 'productivity' 'python' 'rain' 'reading' 'reputed' 'require'\n",
      " 'requires' 'research' 'restaurant' 'rises' 'sat' 'science' 'serves'\n",
      " 'sets' 'space' 'statistics' 'student' 'studies' 'sun' 'sunny'\n",
      " 'technology' 'time' 'today' 'town' 'transforming' 'traveling'\n",
      " 'understand' 'university' 'used' 'versatile' 'vocabulary' 'watching'\n",
      " 'weather' 'weekend' 'weekends' 'west' 'wildlife' 'windowsill' 'world'\n",
      " 'writing']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(bow_feature_names)\n",
    "len(bow_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87b4224-7469-480a-9dca-6b4fc0a0a02a",
   "metadata": {},
   "source": [
    "2. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65ce5c40-8761-436c-bf37-af2814b75d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b9a4b00-ac6c-4f2c-9029-cb0201d8deab",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_tfidf = vectorizer.fit_transform(corpus)\n",
    "tfidf_feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3749fb6a-6de6-4f86-b46d-0a75acee07bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 98)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix_shape = X_tfidf.toarray().shape\n",
    "tfidf_matrix_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65766e9b-c8e7-41c3-b909-100930b5b13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['affecting' 'algorithms' 'artificial' 'baking' 'best' 'birds' 'books'\n",
      " 'bought' 'cakes' 'cat' 'chance' 'change' 'climate' 'coding' 'combines'\n",
      " 'computer' 'cookies' 'course' 'crucial' 'cutting' 'data' 'design'\n",
      " 'domain' 'domains' 'east' 'edge' 'education' 'enjoys' 'expertise'\n",
      " 'exploration' 'football' 'globe' 'graphic' 'helps' 'humans' 'imagination'\n",
      " 'improves' 'intelligence' 'language' 'laptop' 'learning' 'life' 'lot'\n",
      " 'loves' 'machine' 'machines' 'management' 'natural' 'new' 'online'\n",
      " 'opens' 'pandemic' 'paper' 'pasta' 'perspectives' 'playing' 'popular'\n",
      " 'processing' 'productivity' 'python' 'rain' 'reading' 'reputed' 'require'\n",
      " 'requires' 'research' 'restaurant' 'rises' 'sat' 'science' 'serves'\n",
      " 'sets' 'space' 'statistics' 'student' 'studies' 'sun' 'sunny'\n",
      " 'technology' 'time' 'today' 'town' 'transforming' 'traveling'\n",
      " 'understand' 'university' 'used' 'versatile' 'vocabulary' 'watching'\n",
      " 'weather' 'weekend' 'weekends' 'west' 'wildlife' 'windowsill' 'world'\n",
      " 'writing']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tfidf_feature_names)\n",
    "len(tfidf_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebeabac-6bb9-4aec-9e75-3b3f34469f30",
   "metadata": {},
   "source": [
    "3. Word Embeddings (using Word2Vec and SpaCy for document vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f6f2f2d-c67a-42ad-a39d-1397ec748af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "import spacy\n",
    "import pandas as pd\n",
    "# Tokenize corpus for Word2Vec\n",
    "tokenized_corpus = [doc.lower().split() for doc in corpus]\n",
    "\n",
    "# Train Word2Vec model\n",
    "w2v_model = Word2Vec(sentences=tokenized_corpus, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Load SpaCy for averaging word vectors\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "# Compute document vectors by averaging word embeddings\n",
    "doc_vectors = []\n",
    "for doc in corpus:\n",
    "    doc_tokens = nlp(doc.lower())\n",
    "    # Filter out stop words and get vectors for valid tokens\n",
    "    vectors = [w2v_model.wv[token.text] for token in doc_tokens if token.text in w2v_model.wv and not token.is_stop]\n",
    "    if vectors:  # Avoid empty lists\n",
    "        doc_vector = np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        doc_vector = np.zeros(100)  # Fallback for empty documents\n",
    "    doc_vectors.append(doc_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b4d570f-5bb3-485d-a0f5-f161d4f447bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 100)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(doc_vectors).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d88ebb44-7a50-4aa2-9b84-146eb1213871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Matrix (first 5 dimensions for brevity):\n",
      " [[-5.9449705e-03  2.5397690e-03 -1.9819541e-03 -3.9738198e-04\n",
      "  -2.8931843e-03]\n",
      " [-5.1258033e-04  1.8123022e-03 -4.1769901e-03 -2.7964923e-03\n",
      "   5.4746228e-03]\n",
      " [-1.3384543e-03  4.4545578e-04  5.7834503e-03 -6.2623345e-03\n",
      "   3.9122342e-03]\n",
      " [ 2.4398028e-04 -2.0941654e-03  1.0063791e-03  1.2475079e-03\n",
      "  -8.5973454e-04]\n",
      " [-4.3950393e-05 -3.6856607e-03 -3.6310828e-03  4.8191524e-03\n",
      "   8.8849920e-04]\n",
      " [ 4.6248566e-03 -2.7677163e-03 -3.0217292e-03  1.3031758e-03\n",
      "  -2.7077433e-03]\n",
      " [-3.6267913e-03  3.8802449e-04 -1.2668775e-04  2.7124914e-03\n",
      "   1.8422783e-04]\n",
      " [ 2.4062679e-03 -5.1580272e-03  3.2497180e-04 -1.7021465e-03\n",
      "   2.3058681e-03]\n",
      " [-2.9213992e-03  2.8334260e-03 -1.4867997e-03  1.9793171e-03\n",
      "  -4.0567885e-03]\n",
      " [-9.4177981e-04  4.8012575e-04 -3.3727852e-03  2.4738540e-03\n",
      "  -2.0969328e-03]\n",
      " [-3.6363888e-03 -2.1588753e-03 -4.5193117e-03  1.5172813e-03\n",
      "   4.0102378e-03]\n",
      " [ 4.6558939e-03  9.4362884e-05 -2.7358844e-03 -1.5301572e-04\n",
      "   2.3366306e-03]\n",
      " [ 6.3509389e-04 -3.7276971e-03 -5.8353390e-03  1.9087859e-03\n",
      "  -3.5855277e-03]\n",
      " [-2.0861891e-03  3.3053308e-04  3.2399565e-03  7.0231734e-04\n",
      "   2.5941869e-03]\n",
      " [ 1.9684184e-04  1.4627643e-03 -2.9637860e-03 -7.7862591e-03\n",
      "   3.3486835e-03]\n",
      " [ 3.1553768e-03 -1.8362667e-03 -3.3266353e-04 -4.2691603e-03\n",
      "   3.5122005e-04]\n",
      " [-5.0576068e-03  4.7762729e-03 -2.1670603e-03 -3.2329678e-03\n",
      "   3.7339653e-03]\n",
      " [ 1.0724898e-03  4.5775962e-03  2.5677606e-03  7.0805755e-04\n",
      "   4.1703065e-03]\n",
      " [ 4.2242450e-03  2.3413845e-03  4.7314768e-03 -2.3328001e-03\n",
      "   3.8498873e-03]\n",
      " [-5.6259998e-04  6.2173968e-03  8.9634379e-04 -2.2623182e-04\n",
      "  -1.7587855e-04]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Embedding Matrix (first 5 dimensions for brevity):\\n\", np.array(doc_vectors)[:, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fb6ede-5941-418c-a1a1-3684bc007ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rag_env)",
   "language": "python",
   "name": "rag_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
